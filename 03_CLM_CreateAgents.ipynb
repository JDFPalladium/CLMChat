{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed22fb6-a83e-4590-b7f3-def16aaa1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SummaryIndex,\n",
    "    SimpleKeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    Settings\n",
    ")\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac586a1e-22b2-4b81-8a26-80dbed6ce562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-****\"\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-4o\")\n",
    "# service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ad9cb-9837-4d97-bf47-84b6239824f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel sheet\n",
    "docs_df = pd.read_excel(\"CLM_Agents_AutoGen.xlsx\")\n",
    "\n",
    "# Initialize dictionaries to hold the indices and query engines\n",
    "indices = {}\n",
    "summary_indices = {}\n",
    "vector_query_engines = {}\n",
    "summary_query_engines = {}\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for _, row in docs_df.iterrows():\n",
    "    folder_name = row['folder_name']\n",
    "    persist_dir = \"./storage/\" + folder_name#row['index_storage_path']\n",
    "\n",
    "    # Define index names\n",
    "    index_name = f\"{folder_name}_vector\"\n",
    "    summary_index_name = f\"{folder_name}_summary\"\n",
    "\n",
    "    try:\n",
    "        # Load indices from storage\n",
    "        indices[index_name] = load_index_from_storage(StorageContext.from_defaults(persist_dir=persist_dir + \"_vector\"))\n",
    "        summary_indices[summary_index_name] = load_index_from_storage(StorageContext.from_defaults(persist_dir=persist_dir + \"_summary\"))\n",
    "\n",
    "        # Create query engines\n",
    "        vector_query_engines[index_name] = indices[index_name].as_query_engine(similarity_top_k=3)\n",
    "        summary_query_engines[summary_index_name] = summary_indices[summary_index_name].as_query_engine()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading indices for {folder_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6dd4c-5de3-4e52-9cb1-0864b49fd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "# Initialize dictionaries to hold agents\n",
    "agents = {}\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for _, row in docs_df.iterrows():\n",
    "    folder_name = row['folder_name']\n",
    "    \n",
    "    # Construct keys for the query engines\n",
    "    vector_query_engine_key = f\"vector_query_engines['{folder_name}_vector']\"\n",
    "    summary_query_engine_key = f\"summary_query_engines['{folder_name}_summary']\"\n",
    "\n",
    "    try:\n",
    "        # Define tools for the current document\n",
    "        query_engine_tools = [\n",
    "            QueryEngineTool(\n",
    "                query_engine=eval(vector_query_engine_key),  # Access vector query engine\n",
    "                metadata=ToolMetadata(\n",
    "                    name=f\"{folder_name}_vector_tool\",\n",
    "                    description=row['vector_description'],\n",
    "                ),\n",
    "            ),\n",
    "            QueryEngineTool(\n",
    "                query_engine=eval(summary_query_engine_key),  # Access summary query engine\n",
    "                metadata=ToolMetadata(\n",
    "                    name=f\"{folder_name}_summary_tool\",\n",
    "                    description=row['summary_description'],\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Build the agent\n",
    "        function_llm = OpenAI(model=\"gpt-4o\", temperature=0)\n",
    "        agent = OpenAIAgent.from_tools(\n",
    "            query_engine_tools,\n",
    "            llm=function_llm,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Store the agent\n",
    "        agents[f\"{folder_name}\"] = agent\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating agent for {folder_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6826095-017e-4321-9f7b-9f612471ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to hold all tools\n",
    "all_tools = []\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for _, row in docs_df.iterrows():\n",
    "    folder_name = row['folder_name']\n",
    "    \n",
    "    # Define the summary description\n",
    "    top_level_description = row['top_level_description']\n",
    "\n",
    "    # Define tool\n",
    "    doc_tool = QueryEngineTool(\n",
    "        query_engine=agents[f\"{folder_name}\"],\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"tool_{folder_name}\",\n",
    "            description=top_level_description,\n",
    "        ),\n",
    "    )\n",
    "    all_tools.append(doc_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a97fce-6b15-4d40-9a2c-63f2dffa354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an \"object\" index and retriever over these tools\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b56c7d-0ff1-40f2-90b8-5c256b507420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "top_agent = OpenAIAgent.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=3),\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries about community led monitoring (CLM) from guidance from major organizations in the field.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e7dd7-6cac-47ef-83ad-acd8875f1343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
